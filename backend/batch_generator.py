"""æ‰¹é‡NPCå¯¹è¯ç”Ÿæˆå™¨ - ä½¿ç”¨LangChainæ¡†æ¶"""

import os
import json
from datetime import datetime
from typing import Dict, Optional, Any

from agents import NPC_ROLES
from config import settings

# LangChain å¯¼å…¥ - å»¶è¿Ÿå¯¼å…¥
ChatOpenAI = None
ChatPromptTemplate = None

def _import_langchain():
    global ChatOpenAI, ChatPromptTemplate

    try:
        from langchain_openai import ChatOpenAI
    except ImportError as e:
        print(f"âš ï¸ langchain_openai å¯¼å…¥å¤±è´¥: {e}")

    try:
        from langchain_core.prompts import ChatPromptTemplate
    except ImportError as e:
        print(f"âš ï¸ langchain_core.prompts å¯¼å…¥å¤±è´¥: {e}")

_import_langchain()


class NPCBatchGenerator:
    """æ‰¹é‡ç”ŸæˆNPCå¯¹è¯çš„ç”Ÿæˆå™¨

    æ ¸å¿ƒæ€è·¯: ä¸€æ¬¡LLMè°ƒç”¨ç”Ÿæˆæ‰€æœ‰NPCçš„å¯¹è¯,é™ä½APIæˆæœ¬å’Œå»¶è¿Ÿ
    """

    def __init__(self):
        """åˆå§‹åŒ–æ‰¹é‡ç”Ÿæˆå™¨"""
        print("ğŸ¨ æ­£åœ¨åˆå§‹åŒ–æ‰¹é‡å¯¹è¯ç”Ÿæˆå™¨ (LangChain)...")

        self.llm = None
        self.batch_chain = None

        if ChatOpenAI:
            try:
                api_key = settings.LLM_API_KEY
                self.llm = ChatOpenAI(
                    model=settings.LLM_MODEL_ID,
                    api_key=api_key,
                    base_url=settings.LLM_BASE_URL,
                    temperature=0.7
                )

                if ChatPromptTemplate:
                    self.batch_chain = self._create_batch_chain()

                self.enabled = True
                print("âœ… æ‰¹é‡ç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ æ‰¹é‡ç”Ÿæˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                print("âš ï¸  å°†ä½¿ç”¨é¢„è®¾å¯¹è¯æ¨¡å¼")
                self.llm = None
                self.batch_chain = None
                self.enabled = False
        else:
            print("âš ï¸ æœªå®‰è£…langchain-openai, å°†ä½¿ç”¨é¢„è®¾å¯¹è¯æ¨¡å¼")
            self.enabled = False

        self.npc_configs = NPC_ROLES

        # é¢„è®¾å¯¹è¯åº“
        self.preset_dialogues = {
            "morning": {
                "å¼ ä¸‰": "æ—©ä¸Šå¥½!ä»Šå¤©è¦ç»§ç»­ä¼˜åŒ–é‚£ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ€§èƒ½ã€‚",
                "æå››": "æ–°çš„ä¸€å¤©å¼€å§‹äº†,å…ˆæ•´ç†ä¸€ä¸‹ä»Šå¤©çš„ä¼šè®®å®‰æ’ã€‚",
                "ç‹äº”": "æ—©!å…ˆæ¥æ¯å’–å•¡ææç¥,ç„¶åå¼€å§‹è®¾è®¡æ–°ç•Œé¢ã€‚"
            },
            "noon": {
                "å¼ ä¸‰": "å†™äº†ä¸€ä¸Šåˆä»£ç ,ç»ˆäºæŠŠé‚£ä¸ªbugä¿®å¤äº†!",
                "æå››": "ä¸Šåˆçš„éœ€æ±‚è¯„å®¡ä¼šå¾ˆé¡ºåˆ©,ä¸‹åˆç»§ç»­æ¨è¿›ã€‚",
                "ç‹äº”": "è¿™ä¸ªé…è‰²æ–¹æ¡ˆçœ‹èµ·æ¥ä¸é”™,å†è°ƒæ•´ä¸€ä¸‹ç»†èŠ‚ã€‚"
            },
            "afternoon": {
                "å¼ ä¸‰": "ä¸‹åˆç»§ç»­å†™ä»£ç ,è¿™ä¸ªç®—æ³•è¿˜éœ€è¦ä¼˜åŒ–ä¸€ä¸‹ã€‚",
                "æå››": "æ­£åœ¨å‡†å¤‡ä¸‹å‘¨çš„äº§å“è§„åˆ’ä¼š,éœ€æ±‚æ–‡æ¡£å¿«å®Œæˆäº†ã€‚",
                "ç‹äº”": "è®¾è®¡ç¨¿åŸºæœ¬å®Œæˆäº†,ç­‰ä¼šå„¿å‘ç»™å¤§å®¶çœ‹çœ‹ã€‚"
            },
            "evening": {
                "å¼ ä¸‰": "ä»Šå¤©çš„ä»£ç æäº¤å®Œæˆ,æ˜å¤©ç»§ç»­!",
                "æå››": "ä»Šå¤©çš„å·¥ä½œå·®ä¸å¤šäº†,æ•´ç†ä¸€ä¸‹æ˜å¤©çš„å¾…åŠäº‹é¡¹ã€‚",
                "ç‹äº”": "è®¾è®¡å·¥ä½œå‘Šä¸€æ®µè½,æ˜å¤©å†ç»§ç»­ä¼˜åŒ–ã€‚"
            }
        }

    def _create_batch_chain(self):
        """åˆ›å»ºæ‰¹é‡ç”Ÿæˆ LCEL Chain"""
        if not ChatPromptTemplate:
            return None

        prompt = ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆNPCå¯¹è¯ç”Ÿæˆå™¨,æ“…é•¿åˆ›ä½œè‡ªç„¶çœŸå®çš„åŠå…¬å®¤å¯¹è¯ã€‚"),
            ("human", "{input}")
        ])

        chain = prompt | self.llm
        return chain

    def generate_batch_dialogues(self, context: Optional[str] = None) -> Dict[str, str]:
        """æ‰¹é‡ç”Ÿæˆæ‰€æœ‰NPCçš„å¯¹è¯"""
        if not self.enabled or self.llm is None or self.batch_chain is None:
            return self._get_preset_dialogues()

        try:
            prompt = self._build_batch_prompt(context)

            response = self.batch_chain.invoke({"input": prompt})

            if hasattr(response, 'content'):
                response_text = response.content
            else:
                response_text = str(response)

            dialogues = self._parse_response(response_text)

            if dialogues:
                print(f"âœ… æ‰¹é‡ç”ŸæˆæˆåŠŸ: {len(dialogues)}ä¸ªNPCå¯¹è¯")
                return dialogues
            else:
                print("âš ï¸  è§£æå¤±è´¥,ä½¿ç”¨é¢„è®¾å¯¹è¯")
                return self._get_preset_dialogues()

        except Exception as e:
            print(f"âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
            return self._get_preset_dialogues()

    def _build_batch_prompt(self, context: Optional[str] = None) -> str:
        """æ„å»ºæ‰¹é‡ç”Ÿæˆæç¤ºè¯"""
        if context is None:
            context = self._get_current_context()

        npc_descriptions = []
        for name, cfg in self.npc_configs.items():
            desc = f"- {name}({cfg['title']}): åœ¨{cfg['location']}{cfg['activity']},æ€§æ ¼{cfg['personality']}"
            npc_descriptions.append(desc)

        npc_desc_text = "\n".join(npc_descriptions)

        prompt = f"""è¯·ä¸ºDatawhaleåŠå…¬å®¤çš„3ä¸ªNPCç”Ÿæˆå½“å‰çš„å¯¹è¯æˆ–è¡Œä¸ºæè¿°ã€‚

ã€åœºæ™¯ã€‘{context}

ã€NPCä¿¡æ¯ã€‘
{npc_desc_text}

ã€ç”Ÿæˆè¦æ±‚ã€‘
1. æ¯ä¸ªNPCç”Ÿæˆ1å¥è¯(20-40å­—)
2. å†…å®¹è¦ç¬¦åˆè§’è‰²è®¾å®šã€å½“å‰æ´»åŠ¨å’Œåœºæ™¯æ°›å›´
3. å¯ä»¥æ˜¯è‡ªè¨€è‡ªè¯­ã€å·¥ä½œçŠ¶æ€æè¿°ã€æˆ–ç®€å•çš„æ€è€ƒ
4. è¦è‡ªç„¶çœŸå®,åƒçœŸå®çš„åŠå…¬å®¤åŒäº‹
5. å¯ä»¥ä½“ç°ä¸€äº›ä¸ªæ€§åŒ–ç‰¹ç‚¹å’Œæƒ…ç»ª
6. **å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›**

ã€è¾“å‡ºæ ¼å¼ã€‘(ä¸¥æ ¼éµå®ˆ)
{{"å¼ ä¸‰": "...", "æå››": "...", "ç‹äº”": "..."}}

ã€ç¤ºä¾‹è¾“å‡ºã€‘
{{"å¼ ä¸‰": "è¿™ä¸ªbugçœŸæ˜¯è§é¬¼äº†,å·²ç»è°ƒè¯•ä¸¤å°æ—¶äº†...", "æå››": "å—¯,è¿™ä¸ªåŠŸèƒ½çš„ä¼˜å…ˆçº§éœ€è¦é‡æ–°è¯„ä¼°ä¸€ä¸‹ã€‚", "ç‹äº”": "è¿™æ¯å’–å•¡çš„æ‹‰èŠ±çœŸä¸é”™,çµæ„Ÿæ¥äº†!"}}

è¯·ç”Ÿæˆ(åªè¿”å›JSON,ä¸è¦å…¶ä»–å†…å®¹):
"""
        return prompt

    def _parse_response(self, response: str) -> Optional[Dict[str, str]]:
        """è§£æLLMå“åº”"""
        try:
            dialogues = json.loads(response)

            if isinstance(dialogues, dict) and all(name in dialogues for name in self.npc_configs.keys()):
                return dialogues
            else:
                print(f"âš ï¸  JSONæ ¼å¼ä¸æ­£ç¡®: {dialogues}")
                return None

        except json.JSONDecodeError:
            try:
                start = response.find('{')
                end = response.rfind('}') + 1

                if start != -1 and end > start:
                    json_str = response[start:end]
                    dialogues = json.loads(json_str)

                    if isinstance(dialogues, dict):
                        return dialogues
            except:
                pass

            print(f"âš ï¸  æ— æ³•è§£æå“åº”: {response[:100]}...")
            return None

    def _get_current_context(self) -> str:
        """æ ¹æ®å½“å‰æ—¶é—´æ¨æ–­åœºæ™¯ä¸Šä¸‹æ–‡"""
        hour = datetime.now().hour

        if 6 <= hour < 9:
            return "æ¸…æ™¨æ—¶åˆ†,å¤§å®¶é™†ç»­åˆ°è¾¾åŠå…¬å®¤,å‡†å¤‡å¼€å§‹æ–°çš„ä¸€å¤©"
        elif 9 <= hour < 12:
            return "ä¸Šåˆå·¥ä½œæ—¶é—´,å¤§å®¶éƒ½åœ¨ä¸“æ³¨å·¥ä½œ,åŠå…¬å®¤æ°›å›´ä¸“æ³¨è€Œå¿™ç¢Œ"
        elif 12 <= hour < 14:
            return "åˆé¤æ—¶é—´,å¤§å®¶åœ¨ä¼‘æ¯æ”¾æ¾,èŠèŠå¤©æˆ–è€…çœ‹çœ‹æ‰‹æœº"
        elif 14 <= hour < 17:
            return "ä¸‹åˆå·¥ä½œæ—¶é—´,ç»§ç»­æ¨è¿›é¡¹ç›®,å¶å°”éœ€è¦å–æ¯å’–å•¡æç¥"
        elif 17 <= hour < 19:
            return "å‚æ™šæ—¶åˆ†,å‡†å¤‡æ”¶å°¾ä»Šå¤©çš„å·¥ä½œ,æ•´ç†æ˜å¤©çš„è®¡åˆ’"
        else:
            return "å¤œæ™šæ—¶åˆ†,åŠå…¬å®¤å®‰é™ä¸‹æ¥,å¶å°”è¿˜æœ‰äººåœ¨åŠ ç­"

    def _get_preset_dialogues(self) -> Dict[str, str]:
        """è·å–é¢„è®¾å¯¹è¯"""
        hour = datetime.now().hour

        if 6 <= hour < 12:
            period = "morning"
        elif 12 <= hour < 14:
            period = "noon"
        elif 14 <= hour < 18:
            period = "afternoon"
        else:
            period = "evening"

        return self.preset_dialogues.get(period, self.preset_dialogues["morning"])


# å…¨å±€å•ä¾‹
_batch_generator = None


def get_batch_generator() -> "NPCBatchGenerator":
    """è·å–æ‰¹é‡ç”Ÿæˆå™¨å•ä¾‹"""
    global _batch_generator
    if _batch_generator is None:
        _batch_generator = NPCBatchGenerator()
    return _batch_generator
